{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3c385d",
   "metadata": {},
   "source": [
    "# Building the Transformer from scratch\n",
    "\n",
    "In this notebook, we'll be implementing the famous Transformer architecture from scratch\n",
    "\n",
    "The code is based off of the following repos/blog posts:\n",
    "\n",
    "<a href=\"http://nlp.seas.harvard.edu/annotated-transformer/\">The Annotated Transformer</a>\n",
    "\n",
    "<a href=\"https://arxiv.org/abs/1706.03762\">Attention Is All You Need</a>\n",
    "\n",
    "<a href=\"https://keremzaman.com/2020/10/12/role-of-the-target-mask-during-transformer-training/\">Role of the Target Mask during Transformer Training</a>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dcf84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yubaes/anaconda3/envs/DL/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e895d6",
   "metadata": {},
   "source": [
    "One of the keys to understanding how any model works is understanding how the shapes of the tensors change during the processing of each part. We'll be using the logging module to output debugging information to help our understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d56c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('tensor_shapes')\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "# if you want the model to continuously print tensor shapes, set to DEBUG!\n",
    "logger.setLevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa7b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "def getclass():\n",
    "    stack = inspect.stack()\n",
    "    return stack[3][0].f_locals[\"self\"].__class__\n",
    "\n",
    "# A helper function to check how tensor sizes change\n",
    "def log_size(tsr: torch.Tensor, name: str):\n",
    "    cls = getclass()\n",
    "    logger.log(level=cls.level, msg=f\"[{cls.__name__}] {name} size={tsr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74dac27",
   "metadata": {},
   "source": [
    "We'll use logging levels to control the modules we receive output from. The lower the logging level, the more tensor information you'll get. Feel free to play around!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac0d6789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "# Control how much debugging output we want\n",
    "class TensorLoggingLevels(IntEnum):\n",
    "    attention = 1\n",
    "    attention_head = 2\n",
    "    multihead_attention_block = 3\n",
    "    enc_dec_block = 4\n",
    "    enc_dec = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db93f6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We'll be using an enum to refer to dimensions whenever possible to improve readability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47616bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dim(IntEnum):\n",
    "    batch = 0\n",
    "    seq = 1\n",
    "    feature = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b528e47f",
   "metadata": {},
   "source": [
    "\n",
    "# Components\n",
    "\n",
    "# Scaled dot product attention\n",
    "\n",
    "The Transformer is an attention-based architecture. The attention used in the Transformer is the scaled dot product attention, represented by the following formula.\n",
    "                \n",
    "                \n",
    "                attention(Q,K,V) = softmax(QK^T/sqrt(dk)V\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87ae789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    level = TensorLoggingLevels.attention\n",
    "    def __init__(self,dropout:float=0.1)->None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,q:Tensor,k:Tensor,v:Tensor,mask:Tensor=None)->Tensor:\n",
    "        d_k = k.size(-1) # get the size of the key\n",
    "        assert q.size(-1) == d_k\n",
    "        \n",
    "        # Compute the dot product between queries and keys for \n",
    "        # each batch and position in the sequence\n",
    "        attn = torch.bmm(q,k.transpose(Dim.seq,Dim.feature)) # (batch_size,seq_len,seq_len)\n",
    "        #we get an attention score between each position in the sequence for each batch\n",
    "        \n",
    "        # Scale the dot product by the dimentionality\n",
    "        attn = attn/math.sqrt(d_k)\n",
    "        \n",
    "        # normalize the weights across the sequence dimension\n",
    "        # (Note that since we transposed, the sequence and feature dimensions are switched)\n",
    "        attn = torch.exp(attn)\n",
    "        log_size(attn, \"attention weight\") # (batch_size, Seq_len, Seq_len)\n",
    "        \n",
    "        # fill attention weights with 0s where padded\n",
    "        if mask is not None: \n",
    "            attn = attn.masked_fill(mask, 0)\n",
    "        attn = attn / attn.sum(dim=-1, keepdim=True)\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.bmm(attn, v) # (batch_size, seq_len, feature)\n",
    "        log_size(output, \"attention output size\") # (batch_size, seq_len, seq_len)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dbfbf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = ScaledDotProductAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3855da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.rand(5, 10, 20)\n",
    "k = torch.rand(5, 10, 20)\n",
    "v = torch.rand(5, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3592676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ScaledDotProductAttention] attention weight size=torch.Size([5, 10, 10])\n",
      "[ScaledDotProductAttention] attention output size size=torch.Size([5, 10, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6760, 0.4856, 0.4845, 0.5843, 0.4901, 0.6175, 0.8554, 0.6084,\n",
       "          0.6465, 0.5246, 0.6200, 0.6058, 0.5926, 0.7605, 0.5624, 0.4588,\n",
       "          0.4617, 0.5583, 0.5743, 0.6928],\n",
       "         [0.5456, 0.3446, 0.3813, 0.3700, 0.3816, 0.4067, 0.5704, 0.3192,\n",
       "          0.4979, 0.3760, 0.4142, 0.4648, 0.4197, 0.5194, 0.4566, 0.3177,\n",
       "          0.3655, 0.3899, 0.4278, 0.5480],\n",
       "         [0.4954, 0.2710, 0.3246, 0.4519, 0.3532, 0.5428, 0.6357, 0.5354,\n",
       "          0.5623, 0.4407, 0.5359, 0.4190, 0.4410, 0.6435, 0.3971, 0.3051,\n",
       "          0.3373, 0.4196, 0.4540, 0.5259],\n",
       "         [0.6719, 0.4723, 0.4687, 0.5876, 0.4894, 0.5970, 0.8405, 0.6131,\n",
       "          0.6415, 0.5361, 0.6324, 0.5991, 0.5875, 0.7587, 0.5704, 0.4445,\n",
       "          0.4646, 0.5627, 0.5833, 0.6909],\n",
       "         [0.5898, 0.3503, 0.4122, 0.4838, 0.4577, 0.4870, 0.7154, 0.5331,\n",
       "          0.5651, 0.5132, 0.6121, 0.5129, 0.5074, 0.6940, 0.5629, 0.3917,\n",
       "          0.4178, 0.4978, 0.4806, 0.6203],\n",
       "         [0.6786, 0.4878, 0.4807, 0.5815, 0.4947, 0.6302, 0.8395, 0.5969,\n",
       "          0.6471, 0.5388, 0.6216, 0.6214, 0.5782, 0.7608, 0.5590, 0.4630,\n",
       "          0.4731, 0.5671, 0.5904, 0.7035],\n",
       "         [0.5985, 0.3636, 0.4221, 0.4957, 0.4668, 0.5296, 0.7293, 0.5452,\n",
       "          0.5792, 0.5377, 0.6334, 0.5387, 0.5066, 0.7212, 0.5663, 0.4147,\n",
       "          0.4290, 0.5160, 0.4987, 0.6442],\n",
       "         [0.4153, 0.3480, 0.3857, 0.4137, 0.3426, 0.3915, 0.6424, 0.5314,\n",
       "          0.3331, 0.4362, 0.3747, 0.3748, 0.3328, 0.5253, 0.3382, 0.3796,\n",
       "          0.3577, 0.4700, 0.3396, 0.4658],\n",
       "         [0.5889, 0.3612, 0.4089, 0.4889, 0.4481, 0.5098, 0.7211, 0.5245,\n",
       "          0.5758, 0.5016, 0.6239, 0.5226, 0.5181, 0.7029, 0.5628, 0.3945,\n",
       "          0.4028, 0.4866, 0.4835, 0.6234],\n",
       "         [0.6215, 0.4593, 0.3909, 0.4992, 0.4494, 0.5276, 0.7168, 0.5049,\n",
       "          0.5511, 0.4556, 0.6021, 0.6209, 0.5720, 0.6841, 0.5281, 0.4023,\n",
       "          0.4437, 0.4972, 0.5638, 0.6150]],\n",
       "\n",
       "        [[0.3345, 0.5161, 0.5333, 0.3952, 0.3677, 0.3462, 0.5972, 0.4585,\n",
       "          0.5620, 0.4800, 0.3946, 0.5712, 0.4627, 0.5215, 0.5103, 0.5985,\n",
       "          0.5719, 0.5047, 0.4799, 0.5622],\n",
       "         [0.3610, 0.4993, 0.5467, 0.3902, 0.3842, 0.3320, 0.6000, 0.4703,\n",
       "          0.5607, 0.4726, 0.3891, 0.5808, 0.4618, 0.5341, 0.5088, 0.6000,\n",
       "          0.5826, 0.4963, 0.4744, 0.5591],\n",
       "         [0.2302, 0.4321, 0.3917, 0.3268, 0.2564, 0.3097, 0.3975, 0.3176,\n",
       "          0.3788, 0.4444, 0.2641, 0.4619, 0.3258, 0.4446, 0.3432, 0.4420,\n",
       "          0.4196, 0.4151, 0.3328, 0.4655],\n",
       "         [0.4105, 0.5718, 0.5968, 0.4363, 0.4272, 0.3994, 0.6062, 0.4948,\n",
       "          0.5632, 0.5896, 0.4316, 0.6699, 0.4814, 0.6329, 0.5290, 0.6306,\n",
       "          0.6177, 0.6169, 0.4984, 0.5836],\n",
       "         [0.3991, 0.5624, 0.5688, 0.4598, 0.4334, 0.4084, 0.6091, 0.5104,\n",
       "          0.5759, 0.5844, 0.4209, 0.6616, 0.4614, 0.6366, 0.5495, 0.6428,\n",
       "          0.6010, 0.6276, 0.4998, 0.5847],\n",
       "         [0.4056, 0.5646, 0.5801, 0.4485, 0.4273, 0.4014, 0.6145, 0.5075,\n",
       "          0.5765, 0.5730, 0.4296, 0.6590, 0.4734, 0.6315, 0.5517, 0.6421,\n",
       "          0.6125, 0.6218, 0.4998, 0.5800],\n",
       "         [0.3577, 0.3912, 0.4708, 0.3621, 0.3810, 0.2370, 0.4500, 0.4745,\n",
       "          0.4276, 0.4871, 0.2918, 0.5616, 0.3505, 0.4625, 0.3881, 0.4676,\n",
       "          0.4682, 0.3990, 0.4238, 0.4631],\n",
       "         [0.4120, 0.5522, 0.5793, 0.4502, 0.4482, 0.3903, 0.6202, 0.5204,\n",
       "          0.5627, 0.5893, 0.4159, 0.6712, 0.4620, 0.6497, 0.5499, 0.6395,\n",
       "          0.6061, 0.6058, 0.4917, 0.5951],\n",
       "         [0.3991, 0.5731, 0.5860, 0.4423, 0.4299, 0.4035, 0.6218, 0.5013,\n",
       "          0.5773, 0.5761, 0.4337, 0.6629, 0.4774, 0.6322, 0.5520, 0.6423,\n",
       "          0.6124, 0.6237, 0.5014, 0.5856],\n",
       "         [0.3148, 0.5191, 0.5162, 0.4219, 0.4216, 0.3867, 0.5755, 0.4691,\n",
       "          0.5629, 0.5243, 0.3972, 0.6235, 0.4291, 0.5590, 0.5110, 0.5902,\n",
       "          0.5319, 0.5983, 0.4870, 0.5493]],\n",
       "\n",
       "        [[0.6922, 0.6354, 0.5492, 0.5714, 0.4321, 0.6191, 0.5281, 0.5634,\n",
       "          0.4828, 0.4762, 0.6298, 0.6482, 0.4847, 0.4854, 0.5313, 0.4541,\n",
       "          0.5591, 0.6323, 0.4125, 0.3948],\n",
       "         [0.7082, 0.6441, 0.5322, 0.5782, 0.4440, 0.6141, 0.5203, 0.5649,\n",
       "          0.4903, 0.4830, 0.6052, 0.6384, 0.4938, 0.4785, 0.5138, 0.4530,\n",
       "          0.5453, 0.6387, 0.4071, 0.3979],\n",
       "         [0.7046, 0.6444, 0.5308, 0.5787, 0.4449, 0.6206, 0.5241, 0.5653,\n",
       "          0.4896, 0.4750, 0.6086, 0.6390, 0.4824, 0.4790, 0.5221, 0.4691,\n",
       "          0.5438, 0.6474, 0.4028, 0.4014],\n",
       "         [0.7033, 0.6255, 0.5385, 0.5773, 0.4419, 0.6180, 0.5310, 0.5632,\n",
       "          0.4860, 0.4773, 0.6257, 0.6432, 0.4852, 0.4875, 0.5292, 0.4661,\n",
       "          0.5667, 0.6287, 0.4043, 0.3879],\n",
       "         [0.6101, 0.5564, 0.4894, 0.4794, 0.3835, 0.5704, 0.4612, 0.4937,\n",
       "          0.4868, 0.3832, 0.6069, 0.5489, 0.4548, 0.4661, 0.4546, 0.4182,\n",
       "          0.5045, 0.5772, 0.3500, 0.3480],\n",
       "         [0.6218, 0.6159, 0.4513, 0.5415, 0.4268, 0.5295, 0.4273, 0.4934,\n",
       "          0.4342, 0.4143, 0.5175, 0.5450, 0.4066, 0.4711, 0.4259, 0.4488,\n",
       "          0.4777, 0.5754, 0.3331, 0.3512],\n",
       "         [0.7012, 0.5484, 0.4574, 0.5406, 0.4438, 0.6014, 0.5100, 0.5114,\n",
       "          0.4811, 0.4784, 0.5443, 0.5849, 0.4672, 0.3759, 0.4178, 0.4413,\n",
       "          0.4669, 0.5664, 0.3595, 0.3615],\n",
       "         [0.6972, 0.6498, 0.5370, 0.5734, 0.4404, 0.6201, 0.5233, 0.5688,\n",
       "          0.4895, 0.4722, 0.6149, 0.6408, 0.4841, 0.4837, 0.5260, 0.4641,\n",
       "          0.5443, 0.6508, 0.4059, 0.4058],\n",
       "         [0.5947, 0.6378, 0.5030, 0.5022, 0.4216, 0.5259, 0.4552, 0.5689,\n",
       "          0.4329, 0.4649, 0.5723, 0.5876, 0.4711, 0.4863, 0.4377, 0.3605,\n",
       "          0.5039, 0.5511, 0.3862, 0.3932],\n",
       "         [0.5933, 0.6059, 0.5205, 0.4936, 0.3899, 0.5234, 0.5059, 0.5571,\n",
       "          0.3960, 0.4607, 0.5995, 0.6270, 0.4106, 0.4573, 0.5113, 0.4554,\n",
       "          0.5157, 0.6198, 0.3613, 0.3732]],\n",
       "\n",
       "        [[0.5950, 0.4331, 0.5149, 0.3906, 0.5387, 0.3544, 0.7628, 0.4330,\n",
       "          0.5962, 0.5157, 0.4599, 0.4255, 0.5606, 0.5460, 0.4768, 0.6068,\n",
       "          0.5415, 0.4617, 0.5042, 0.5963],\n",
       "         [0.6587, 0.5289, 0.5606, 0.4380, 0.5501, 0.3809, 0.8049, 0.4859,\n",
       "          0.6025, 0.5770, 0.5569, 0.4907, 0.6074, 0.5382, 0.5603, 0.7087,\n",
       "          0.6329, 0.5080, 0.6063, 0.5996],\n",
       "         [0.6647, 0.5249, 0.5603, 0.4272, 0.5665, 0.3882, 0.8105, 0.4976,\n",
       "          0.6175, 0.5766, 0.5563, 0.4889, 0.5998, 0.5600, 0.5505, 0.7070,\n",
       "          0.6264, 0.5043, 0.5991, 0.6233],\n",
       "         [0.5852, 0.4958, 0.5372, 0.3825, 0.4929, 0.3599, 0.7643, 0.4543,\n",
       "          0.5785, 0.5414, 0.5140, 0.4438, 0.5444, 0.5295, 0.4917, 0.6774,\n",
       "          0.5437, 0.4978, 0.5395, 0.5630],\n",
       "         [0.6785, 0.5146, 0.5616, 0.4212, 0.5734, 0.3781, 0.8102, 0.4918,\n",
       "          0.6092, 0.5803, 0.5552, 0.4878, 0.5997, 0.5647, 0.5522, 0.6884,\n",
       "          0.6239, 0.5140, 0.5938, 0.6328],\n",
       "         [0.6800, 0.5101, 0.5607, 0.4224, 0.5616, 0.3707, 0.8043, 0.4937,\n",
       "          0.6078, 0.5823, 0.5504, 0.4966, 0.6009, 0.5519, 0.5622, 0.7059,\n",
       "          0.6200, 0.5177, 0.5907, 0.6148],\n",
       "         [0.5839, 0.4944, 0.5203, 0.4040, 0.5604, 0.3288, 0.7106, 0.4363,\n",
       "          0.5049, 0.5343, 0.5185, 0.4364, 0.4906, 0.5220, 0.4777, 0.6022,\n",
       "          0.5266, 0.4387, 0.5358, 0.5682],\n",
       "         [0.6676, 0.4546, 0.5156, 0.3258, 0.5310, 0.3115, 0.7206, 0.4822,\n",
       "          0.5711, 0.5817, 0.5308, 0.4148, 0.5260, 0.5142, 0.4535, 0.6549,\n",
       "          0.5245, 0.4446, 0.5648, 0.6206],\n",
       "         [0.6074, 0.4166, 0.4897, 0.4144, 0.4571, 0.2616, 0.6780, 0.4320,\n",
       "          0.4943, 0.5281, 0.4716, 0.4413, 0.5482, 0.4242, 0.5223, 0.6355,\n",
       "          0.5867, 0.4761, 0.4429, 0.4830],\n",
       "         [0.5647, 0.4913, 0.5113, 0.4166, 0.5361, 0.3219, 0.6984, 0.4240,\n",
       "          0.4884, 0.5225, 0.5094, 0.4382, 0.4951, 0.4929, 0.4888, 0.6051,\n",
       "          0.5340, 0.4352, 0.5301, 0.5297]],\n",
       "\n",
       "        [[0.4171, 0.4535, 0.6045, 0.4512, 0.3754, 0.5364, 0.5363, 0.3602,\n",
       "          0.6711, 0.3281, 0.4175, 0.4415, 0.5725, 0.5348, 0.4054, 0.4287,\n",
       "          0.2737, 0.5481, 0.3967, 0.5686],\n",
       "         [0.4310, 0.5299, 0.6535, 0.4490, 0.4277, 0.5595, 0.5756, 0.4431,\n",
       "          0.6844, 0.3695, 0.4275, 0.5350, 0.5991, 0.5443, 0.4192, 0.4643,\n",
       "          0.2976, 0.5923, 0.3976, 0.6001],\n",
       "         [0.4320, 0.5072, 0.6491, 0.4443, 0.4260, 0.5821, 0.5499, 0.4508,\n",
       "          0.6802, 0.3861, 0.4118, 0.5326, 0.5795, 0.5224, 0.4034, 0.4531,\n",
       "          0.3077, 0.6045, 0.3997, 0.5996],\n",
       "         [0.3433, 0.3753, 0.4893, 0.3504, 0.3592, 0.4035, 0.3609, 0.3947,\n",
       "          0.5269, 0.3043, 0.2942, 0.4821, 0.4721, 0.3612, 0.2743, 0.3180,\n",
       "          0.2469, 0.4554, 0.2548, 0.4519],\n",
       "         [0.2689, 0.2961, 0.4335, 0.2894, 0.2781, 0.3731, 0.3549, 0.3651,\n",
       "          0.5026, 0.2495, 0.2748, 0.4408, 0.4013, 0.2992, 0.2765, 0.2751,\n",
       "          0.2206, 0.4090, 0.2266, 0.4368],\n",
       "         [0.4177, 0.5050, 0.6494, 0.4455, 0.4212, 0.5897, 0.5601, 0.4561,\n",
       "          0.6694, 0.3780, 0.4154, 0.5224, 0.5802, 0.5265, 0.3979, 0.4491,\n",
       "          0.3165, 0.5903, 0.4121, 0.5921],\n",
       "         [0.4007, 0.4536, 0.5950, 0.4425, 0.3688, 0.5239, 0.5394, 0.3584,\n",
       "          0.6527, 0.3121, 0.4026, 0.4432, 0.5861, 0.5233, 0.3989, 0.4190,\n",
       "          0.2597, 0.5361, 0.3910, 0.5585],\n",
       "         [0.3888, 0.3906, 0.5140, 0.3912, 0.3438, 0.4423, 0.4176, 0.3421,\n",
       "          0.6337, 0.3088, 0.3345, 0.4405, 0.5183, 0.4331, 0.3113, 0.3916,\n",
       "          0.2692, 0.5089, 0.3196, 0.5374],\n",
       "         [0.4419, 0.5273, 0.6490, 0.4454, 0.4331, 0.5642, 0.5495, 0.4431,\n",
       "          0.6748, 0.3810, 0.4064, 0.5322, 0.5938, 0.5305, 0.3974, 0.4640,\n",
       "          0.3021, 0.5991, 0.3943, 0.5950],\n",
       "         [0.4163, 0.4055, 0.5522, 0.4311, 0.3563, 0.4385, 0.4495, 0.2937,\n",
       "          0.6564, 0.2866, 0.3409, 0.4233, 0.5153, 0.4876, 0.3762, 0.3991,\n",
       "          0.1894, 0.5068, 0.2874, 0.5136]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b567f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fd83edf",
   "metadata": {},
   "source": [
    "\n",
    "# Multi-Head Attention\n",
    "\n",
    "Now, we turn to the core component in the Transformer architecture: the multi-head attention block. This block applies linear transformations to the input, then applies scaled dot product attention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e23a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    level = TensorLoggingLevels.attention_head\n",
    "    def __init__(self,d_model:int,d_feature:int,dropout:float=0.1)->None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = ScaledDotProductAttention(dropout)\n",
    "        self.Q = nn.Linear(d_model,d_feature)\n",
    "        self.K = nn.Linear(d_model,d_feature)\n",
    "        self.V = nn.Linear(d_model,d_feature)\n",
    "    \n",
    "    def forward(self,q:Tensor,k:Tensor,v:Tensor,mask:Tensor=None)->Tensor:\n",
    "        query = self.Q(q) # (batch_size,seq,feature)\n",
    "        key = self.K(k)   # (batch_size,seq,feature)\n",
    "        value = self.V(v) # (batch_size,seq,feature)\n",
    "        log_size(query,\"queries,keys,values\")\n",
    "        return self.attn(query,key,value)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d06cb0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[AttentionHead] queries,keys,values size=torch.Size([5, 10, 20])\n",
      "[ScaledDotProductAttention] attention weight size=torch.Size([5, 10, 10])\n",
      "[ScaledDotProductAttention] attention output size size=torch.Size([5, 10, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.9640e-01,  5.2956e-01,  1.1770e-03,  7.5713e-02,  5.1480e-01,\n",
       "           1.1813e-01,  7.2734e-02, -4.2564e-01, -1.9428e-01,  3.5302e-01,\n",
       "          -3.1689e-01,  3.5237e-02, -6.9424e-01, -5.5099e-01,  4.2387e-01,\n",
       "          -4.5039e-01, -2.7075e-01,  4.8245e-01,  5.0978e-01,  1.8877e-03],\n",
       "         [ 5.9622e-01,  5.3147e-01,  6.4796e-04,  7.6590e-02,  5.1329e-01,\n",
       "           1.1826e-01,  7.4331e-02, -4.2290e-01, -1.9048e-01,  3.5191e-01,\n",
       "          -3.1679e-01,  3.4965e-02, -6.9292e-01, -5.5001e-01,  4.2325e-01,\n",
       "          -4.5194e-01, -2.6899e-01,  4.8235e-01,  5.1077e-01, -2.4627e-04],\n",
       "         [ 5.9682e-01,  5.3452e-01,  1.4155e-03,  7.5207e-02,  5.1304e-01,\n",
       "           1.1663e-01,  7.3342e-02, -4.2723e-01, -1.8908e-01,  3.5151e-01,\n",
       "          -3.1971e-01,  3.3672e-02, -6.9690e-01, -5.4693e-01,  4.2368e-01,\n",
       "          -4.5345e-01, -2.7034e-01,  4.8447e-01,  5.1332e-01,  2.0362e-03],\n",
       "         [ 5.1626e-01,  4.9480e-01,  2.1129e-02,  1.0486e-01,  4.7905e-01,\n",
       "           7.8520e-02,  6.7380e-02, -3.8182e-01, -1.4977e-01,  2.8343e-01,\n",
       "          -2.9596e-01,  1.8139e-02, -6.5530e-01, -5.0112e-01,  4.0448e-01,\n",
       "          -4.4200e-01, -2.5533e-01,  4.2981e-01,  4.7669e-01,  9.3577e-03],\n",
       "         [ 5.2141e-01,  5.0101e-01,  2.3844e-02,  1.0216e-01,  4.8415e-01,\n",
       "           8.0140e-02,  6.6916e-02, -3.8859e-01, -1.5147e-01,  2.8916e-01,\n",
       "          -3.0048e-01,  1.6969e-02, -6.6246e-01, -5.0343e-01,  4.0829e-01,\n",
       "          -4.4564e-01, -2.5979e-01,  4.3324e-01,  4.8114e-01,  1.1274e-02],\n",
       "         [ 4.1014e-01,  3.4087e-01, -1.0957e-02,  8.2329e-02,  3.4319e-01,\n",
       "           5.8951e-02,  1.8431e-02, -3.1092e-01, -1.4355e-01,  2.0693e-01,\n",
       "          -2.2264e-01,  4.6787e-02, -4.8683e-01, -3.9694e-01,  2.8281e-01,\n",
       "          -2.9002e-01, -1.5775e-01,  3.6606e-01,  3.4033e-01, -2.7718e-02],\n",
       "         [ 5.3636e-01,  5.0240e-01,  2.2250e-03,  7.1735e-02,  4.6596e-01,\n",
       "           7.9383e-02,  5.6934e-02, -3.9657e-01, -1.3852e-01,  3.0477e-01,\n",
       "          -3.0366e-01,  2.0021e-02, -6.4527e-01, -4.7982e-01,  3.7723e-01,\n",
       "          -4.3147e-01, -2.3704e-01,  4.5345e-01,  4.7030e-01, -1.8423e-02],\n",
       "         [ 5.5487e-01,  4.6897e-01,  4.0631e-03,  5.2290e-02,  4.7738e-01,\n",
       "           1.2055e-01,  6.4697e-02, -3.4163e-01, -1.6781e-01,  3.1444e-01,\n",
       "          -2.8582e-01,  4.2043e-02, -6.4290e-01, -4.8858e-01,  3.7306e-01,\n",
       "          -4.3775e-01, -2.5645e-01,  4.3270e-01,  4.7916e-01, -9.1708e-03],\n",
       "         [ 5.0920e-01,  5.0014e-01, -1.3387e-02,  6.6546e-02,  4.5477e-01,\n",
       "           1.2616e-01,  9.8064e-02, -3.5653e-01, -1.4253e-01,  3.0215e-01,\n",
       "          -2.8356e-01,  4.8032e-02, -6.2653e-01, -5.1156e-01,  4.0218e-01,\n",
       "          -4.1988e-01, -2.4599e-01,  4.3151e-01,  4.5606e-01,  1.7131e-02],\n",
       "         [ 5.0852e-01,  5.0060e-01, -1.4821e-02,  6.5594e-02,  4.5022e-01,\n",
       "           1.2454e-01,  9.7830e-02, -3.6156e-01, -1.4236e-01,  3.0316e-01,\n",
       "          -2.8306e-01,  4.6115e-02, -6.2308e-01, -5.0723e-01,  3.9968e-01,\n",
       "          -4.1530e-01, -2.4327e-01,  4.3182e-01,  4.5448e-01,  1.8275e-02]],\n",
       "\n",
       "        [[ 3.1748e-01,  3.9315e-01, -8.0898e-02,  8.7699e-02,  2.9800e-01,\n",
       "           8.5195e-02,  3.4803e-02, -2.1189e-01, -4.4178e-02,  1.5876e-01,\n",
       "          -2.0345e-01, -1.9286e-03, -4.9187e-01, -3.8306e-01,  2.4212e-01,\n",
       "          -3.2518e-01, -1.4270e-01,  3.5402e-01,  3.5652e-01,  3.7327e-02],\n",
       "         [ 3.7999e-01,  4.3206e-01, -6.8502e-02,  1.0312e-01,  2.9961e-01,\n",
       "           7.2196e-02,  1.4126e-02, -2.4619e-01, -5.7104e-02,  1.9084e-01,\n",
       "          -2.1788e-01, -6.6492e-03, -5.7594e-01, -4.1719e-01,  2.7812e-01,\n",
       "          -3.9585e-01, -1.6124e-01,  3.6131e-01,  4.3024e-01,  7.2818e-02],\n",
       "         [ 3.8780e-01,  5.2414e-01, -1.2978e-01,  9.9097e-02,  3.6732e-01,\n",
       "           9.6126e-02,  4.6186e-02, -2.8809e-01, -5.1903e-03,  1.7367e-01,\n",
       "          -2.3169e-01,  1.1951e-03, -6.5089e-01, -4.4087e-01,  2.9590e-01,\n",
       "          -4.3037e-01, -1.5709e-01,  4.5749e-01,  4.4752e-01,  2.0886e-02],\n",
       "         [ 4.3290e-01,  5.0853e-01, -1.1341e-01,  1.1356e-01,  3.4843e-01,\n",
       "           1.0677e-01,  1.7491e-02, -3.0377e-01, -2.7859e-02,  1.8220e-01,\n",
       "          -2.2758e-01,  2.5925e-02, -6.5478e-01, -4.3807e-01,  2.9571e-01,\n",
       "          -4.5824e-01, -1.5875e-01,  4.4574e-01,  4.6160e-01,  4.0246e-02],\n",
       "         [ 4.4793e-01,  5.5879e-01, -1.3609e-01,  1.1993e-01,  4.1023e-01,\n",
       "           9.0424e-02,  2.3806e-02, -3.2451e-01, -2.3350e-02,  1.8676e-01,\n",
       "          -2.5217e-01,  1.5823e-02, -7.4272e-01, -4.9315e-01,  3.2916e-01,\n",
       "          -5.0689e-01, -1.9292e-01,  4.9442e-01,  5.0354e-01,  4.2581e-02],\n",
       "         [ 3.7115e-01,  4.8262e-01, -1.1414e-01,  1.1852e-01,  3.6048e-01,\n",
       "           5.5854e-02, -7.0578e-03, -2.9413e-01,  3.6843e-03,  1.2204e-01,\n",
       "          -2.0439e-01,  2.5086e-02, -7.1704e-01, -4.2653e-01,  2.8237e-01,\n",
       "          -4.9056e-01, -1.5559e-01,  4.4789e-01,  4.5505e-01,  1.7636e-02],\n",
       "         [ 4.3121e-01,  5.0939e-01, -1.1389e-01,  1.1439e-01,  3.4778e-01,\n",
       "           1.0780e-01,  1.7795e-02, -3.0129e-01, -2.6393e-02,  1.8058e-01,\n",
       "          -2.2452e-01,  2.6217e-02, -6.5351e-01, -4.3669e-01,  2.9449e-01,\n",
       "          -4.5842e-01, -1.5793e-01,  4.4506e-01,  4.6112e-01,  3.7566e-02],\n",
       "         [ 4.5024e-01,  5.5443e-01, -1.3155e-01,  1.1731e-01,  4.1034e-01,\n",
       "           8.8213e-02,  2.5343e-02, -3.2615e-01, -2.5834e-02,  1.8632e-01,\n",
       "          -2.5780e-01,  1.4693e-02, -7.4227e-01, -4.9408e-01,  3.3068e-01,\n",
       "          -5.0521e-01, -1.9450e-01,  4.9296e-01,  5.0394e-01,  4.6309e-02],\n",
       "         [ 3.9007e-01,  5.2811e-01, -1.2959e-01,  1.0025e-01,  3.6851e-01,\n",
       "           9.6650e-02,  4.6916e-02, -2.8796e-01, -3.7118e-03,  1.7332e-01,\n",
       "          -2.3150e-01,  3.2080e-04, -6.5283e-01, -4.4163e-01,  2.9689e-01,\n",
       "          -4.3280e-01, -1.5785e-01,  4.5802e-01,  4.5029e-01,  1.9806e-02],\n",
       "         [ 4.3240e-01,  5.0695e-01, -1.0882e-01,  9.4312e-02,  3.8583e-01,\n",
       "           8.6432e-02,  5.0750e-02, -2.8238e-01, -3.1030e-02,  1.5970e-01,\n",
       "          -2.3426e-01,  1.5746e-02, -6.7292e-01, -4.5413e-01,  3.1074e-01,\n",
       "          -4.7122e-01, -1.9866e-01,  4.3995e-01,  4.7195e-01,  3.9986e-02]],\n",
       "\n",
       "        [[ 4.3011e-01,  4.7651e-01, -8.4973e-02,  1.1560e-01,  3.8999e-01,\n",
       "           2.4275e-02,  4.9440e-02, -4.0928e-01, -1.4363e-01,  3.3127e-01,\n",
       "          -2.2373e-01,  1.7768e-02, -7.3699e-01, -4.9484e-01,  3.7768e-01,\n",
       "          -4.4176e-01, -1.9526e-01,  4.3864e-01,  5.2908e-01,  6.4997e-02],\n",
       "         [ 2.7037e-01,  3.4770e-01, -1.0554e-01,  9.5089e-02,  2.6787e-01,\n",
       "          -8.5129e-03,  4.6580e-02, -2.5154e-01, -5.3599e-02,  1.9042e-01,\n",
       "          -9.0233e-02, -8.9261e-03, -5.5308e-01, -3.1934e-01,  2.5562e-01,\n",
       "          -3.1534e-01, -1.3254e-01,  2.7986e-01,  3.5599e-01,  6.5078e-02],\n",
       "         [ 4.0537e-01,  4.0469e-01, -6.8144e-02,  1.1398e-01,  3.4412e-01,\n",
       "           3.1832e-02,  1.9363e-02, -3.5173e-01, -1.4396e-01,  3.0824e-01,\n",
       "          -1.8374e-01,  2.8880e-02, -6.6322e-01, -4.3871e-01,  3.3165e-01,\n",
       "          -4.0365e-01, -1.6581e-01,  3.8082e-01,  4.7267e-01,  4.6019e-02],\n",
       "         [ 4.2992e-01,  4.7675e-01, -8.5812e-02,  1.1590e-01,  3.9031e-01,\n",
       "           2.3412e-02,  4.9701e-02, -4.0926e-01, -1.4305e-01,  3.3098e-01,\n",
       "          -2.2206e-01,  1.6855e-02, -7.3662e-01, -4.9442e-01,  3.7721e-01,\n",
       "          -4.4133e-01, -1.9550e-01,  4.3712e-01,  5.2830e-01,  6.4757e-02],\n",
       "         [ 4.2791e-01,  4.7404e-01, -8.5088e-02,  1.1540e-01,  3.9222e-01,\n",
       "           2.2211e-02,  5.1155e-02, -4.0982e-01, -1.4263e-01,  3.2882e-01,\n",
       "          -2.2352e-01,  1.5828e-02, -7.3571e-01, -4.9452e-01,  3.7595e-01,\n",
       "          -4.4135e-01, -1.9551e-01,  4.3770e-01,  5.2743e-01,  6.4834e-02],\n",
       "         [ 3.7771e-01,  3.4391e-01, -3.9818e-02,  1.0742e-01,  2.8040e-01,\n",
       "           2.3515e-02,  3.2945e-02, -3.2553e-01, -1.2206e-01,  2.7425e-01,\n",
       "          -1.8624e-01,  1.6101e-02, -5.5413e-01, -3.8654e-01,  2.8509e-01,\n",
       "          -3.0565e-01, -1.1308e-01,  3.4361e-01,  4.1540e-01,  4.9563e-02],\n",
       "         [ 3.4291e-01,  3.9380e-01, -6.3315e-02,  7.7416e-02,  3.8308e-01,\n",
       "           5.6982e-03,  3.2953e-02, -3.7198e-01, -1.2276e-01,  2.8306e-01,\n",
       "          -2.1792e-01,  3.3870e-03, -6.6538e-01, -4.3920e-01,  3.1939e-01,\n",
       "          -4.2099e-01, -1.8418e-01,  3.9292e-01,  4.6100e-01,  4.4887e-02],\n",
       "         [ 3.8100e-01,  4.3694e-01, -1.0331e-01,  1.1030e-01,  3.6695e-01,\n",
       "          -1.0175e-02,  4.9590e-02, -3.7615e-01, -1.1406e-01,  2.9411e-01,\n",
       "          -1.6255e-01,  7.1876e-03, -6.7274e-01, -4.5050e-01,  3.4198e-01,\n",
       "          -3.8006e-01, -1.8781e-01,  3.7285e-01,  4.4443e-01,  6.1036e-02],\n",
       "         [ 4.3139e-01,  4.7299e-01, -8.2683e-02,  1.1615e-01,  3.8750e-01,\n",
       "           2.6619e-02,  4.8246e-02, -4.0853e-01, -1.4535e-01,  3.3050e-01,\n",
       "          -2.2577e-01,  1.8414e-02, -7.3643e-01, -4.9489e-01,  3.7576e-01,\n",
       "          -4.4157e-01, -1.9241e-01,  4.4033e-01,  5.3100e-01,  6.5821e-02],\n",
       "         [ 4.0804e-01,  4.1975e-01, -5.6527e-02,  1.1177e-01,  3.2532e-01,\n",
       "           1.7228e-02,  6.4536e-02, -3.8649e-01, -1.2179e-01,  2.9939e-01,\n",
       "          -2.2794e-01,  3.0026e-03, -6.3312e-01, -4.4688e-01,  3.3244e-01,\n",
       "          -3.4399e-01, -1.3962e-01,  4.0551e-01,  4.7803e-01,  7.0667e-02]],\n",
       "\n",
       "        [[ 3.8122e-01,  3.4044e-01, -1.1676e-01, -2.0711e-02,  2.8520e-01,\n",
       "           9.0331e-02,  6.1100e-02, -3.5566e-01, -1.0047e-01,  1.7076e-01,\n",
       "          -2.7536e-01,  7.4519e-02, -5.7267e-01, -4.0322e-01,  2.5467e-01,\n",
       "          -3.4327e-01, -1.5873e-01,  4.4181e-01,  3.7531e-01,  1.3950e-01],\n",
       "         [ 5.0499e-01,  4.8157e-01, -1.3123e-01, -6.5679e-03,  3.8432e-01,\n",
       "           1.0034e-01,  1.0529e-01, -4.2873e-01, -9.7956e-02,  2.3868e-01,\n",
       "          -3.4098e-01,  6.9918e-02, -7.1140e-01, -4.9311e-01,  3.6449e-01,\n",
       "          -4.1457e-01, -2.0513e-01,  5.2813e-01,  4.6197e-01,  1.3408e-01],\n",
       "         [ 4.4890e-01,  4.2932e-01, -1.2415e-01, -1.7369e-02,  3.5862e-01,\n",
       "           7.8395e-02,  1.1168e-01, -3.9266e-01, -7.8160e-02,  2.0504e-01,\n",
       "          -2.8131e-01,  4.8392e-02, -6.3117e-01, -4.1244e-01,  3.1912e-01,\n",
       "          -3.8274e-01, -1.9766e-01,  4.3381e-01,  4.1557e-01,  1.1665e-01],\n",
       "         [ 4.4692e-01,  4.2764e-01, -1.2513e-01, -1.6847e-02,  3.5632e-01,\n",
       "           7.7359e-02,  1.1302e-01, -3.9077e-01, -7.8207e-02,  2.0502e-01,\n",
       "          -2.8144e-01,  4.6579e-02, -6.2884e-01, -4.1119e-01,  3.1851e-01,\n",
       "          -3.8133e-01, -1.9686e-01,  4.3268e-01,  4.1514e-01,  1.1958e-01],\n",
       "         [ 4.5180e-01,  4.4582e-01, -1.0504e-01, -2.1648e-02,  3.6816e-01,\n",
       "           9.2868e-02,  8.5188e-02, -3.9336e-01, -8.7401e-02,  2.3333e-01,\n",
       "          -3.0132e-01,  7.6721e-02, -6.6001e-01, -4.4517e-01,  3.4150e-01,\n",
       "          -3.8850e-01, -1.9820e-01,  4.7505e-01,  4.0999e-01,  9.4871e-02],\n",
       "         [ 5.0459e-01,  4.8288e-01, -1.2918e-01, -8.7040e-03,  3.8646e-01,\n",
       "           9.8380e-02,  1.0527e-01, -4.3003e-01, -9.6830e-02,  2.4223e-01,\n",
       "          -3.4298e-01,  6.8376e-02, -7.1105e-01, -4.9306e-01,  3.6662e-01,\n",
       "          -4.1233e-01, -2.0629e-01,  5.2627e-01,  4.5959e-01,  1.3361e-01],\n",
       "         [ 5.0618e-01,  4.8075e-01, -1.3015e-01, -6.6902e-03,  3.8463e-01,\n",
       "           1.0087e-01,  1.0354e-01, -4.3100e-01, -9.9910e-02,  2.3919e-01,\n",
       "          -3.4176e-01,  7.1378e-02, -7.1028e-01, -4.9500e-01,  3.6459e-01,\n",
       "          -4.1429e-01, -2.0604e-01,  5.2796e-01,  4.6073e-01,  1.3412e-01],\n",
       "         [ 5.0613e-01,  4.8217e-01, -1.2926e-01, -6.4237e-03,  3.8590e-01,\n",
       "           9.8694e-02,  1.0460e-01, -4.3162e-01, -9.9347e-02,  2.4182e-01,\n",
       "          -3.4268e-01,  6.8991e-02, -7.0912e-01, -4.9465e-01,  3.6692e-01,\n",
       "          -4.1207e-01, -2.0730e-01,  5.2512e-01,  4.5934e-01,  1.3513e-01],\n",
       "         [ 5.0594e-01,  4.8044e-01, -1.3247e-01, -2.8172e-03,  3.8100e-01,\n",
       "           1.0318e-01,  1.0211e-01, -4.2841e-01, -1.0053e-01,  2.3582e-01,\n",
       "          -3.4004e-01,  7.2533e-02, -7.1142e-01, -4.9540e-01,  3.6182e-01,\n",
       "          -4.1575e-01, -2.0294e-01,  5.3215e-01,  4.6419e-01,  1.3393e-01],\n",
       "         [ 5.0358e-01,  4.8107e-01, -1.2956e-01, -1.0056e-02,  3.8731e-01,\n",
       "           9.9690e-02,  1.0394e-01, -4.3110e-01, -9.8138e-02,  2.4116e-01,\n",
       "          -3.4235e-01,  7.1484e-02, -7.1341e-01, -4.9464e-01,  3.6580e-01,\n",
       "          -4.1367e-01, -2.0731e-01,  5.2793e-01,  4.5948e-01,  1.3408e-01]],\n",
       "\n",
       "        [[ 4.5120e-01,  3.8912e-01, -1.4727e-01,  8.3432e-02,  2.9100e-01,\n",
       "           5.7458e-02, -3.2536e-02, -3.4239e-01, -6.1699e-02,  2.4674e-01,\n",
       "          -1.7329e-01,  4.2668e-02, -5.6229e-01, -3.9101e-01,  2.0442e-01,\n",
       "          -3.1267e-01, -5.8388e-02,  3.9665e-01,  4.1349e-01, -3.4604e-02],\n",
       "         [ 5.2435e-01,  4.7117e-01, -1.2487e-01,  1.0322e-01,  3.1737e-01,\n",
       "           7.4245e-02, -3.5790e-02, -3.7402e-01, -5.9816e-02,  2.7578e-01,\n",
       "          -2.3546e-01,  4.0324e-02, -6.3400e-01, -4.4269e-01,  2.6246e-01,\n",
       "          -3.5732e-01, -7.5768e-02,  4.4764e-01,  4.7916e-01, -2.4281e-02],\n",
       "         [ 5.2049e-01,  4.7088e-01, -1.2378e-01,  1.0481e-01,  3.1891e-01,\n",
       "           7.3725e-02, -3.4961e-02, -3.7319e-01, -5.8626e-02,  2.7478e-01,\n",
       "          -2.3494e-01,  4.0138e-02, -6.3172e-01, -4.4424e-01,  2.6392e-01,\n",
       "          -3.5863e-01, -7.6424e-02,  4.4435e-01,  4.7722e-01, -2.5574e-02],\n",
       "         [ 5.2441e-01,  4.6975e-01, -1.2285e-01,  1.0250e-01,  3.2093e-01,\n",
       "           7.5695e-02, -3.4306e-02, -3.7368e-01, -6.2918e-02,  2.7661e-01,\n",
       "          -2.3597e-01,  3.9972e-02, -6.3247e-01, -4.4292e-01,  2.6493e-01,\n",
       "          -3.6041e-01, -7.9515e-02,  4.4401e-01,  4.7853e-01, -2.4200e-02],\n",
       "         [ 5.2226e-01,  4.7248e-01, -1.2452e-01,  1.0500e-01,  3.1706e-01,\n",
       "           7.1949e-02, -3.3590e-02, -3.7483e-01, -5.7844e-02,  2.7323e-01,\n",
       "          -2.3488e-01,  3.7854e-02, -6.3190e-01, -4.4266e-01,  2.6338e-01,\n",
       "          -3.5760e-01, -7.5931e-02,  4.4459e-01,  4.7829e-01, -2.4580e-02],\n",
       "         [ 5.2112e-01,  4.7194e-01, -1.2370e-01,  1.0539e-01,  3.1818e-01,\n",
       "           7.2973e-02, -3.4210e-02, -3.7401e-01, -5.8256e-02,  2.7393e-01,\n",
       "          -2.3532e-01,  3.8733e-02, -6.3135e-01, -4.4373e-01,  2.6413e-01,\n",
       "          -3.5822e-01, -7.6305e-02,  4.4413e-01,  4.7759e-01, -2.5174e-02],\n",
       "         [ 4.5292e-01,  4.3053e-01, -7.0197e-02,  8.6072e-02,  3.0187e-01,\n",
       "           6.9490e-02, -2.7776e-02, -3.1505e-01, -4.1917e-02,  2.5896e-01,\n",
       "          -2.4218e-01,  3.8613e-02, -5.6779e-01, -4.1979e-01,  2.6934e-01,\n",
       "          -3.4668e-01, -8.8581e-02,  3.7340e-01,  4.3483e-01, -2.3045e-02],\n",
       "         [ 4.5168e-01,  3.8850e-01, -1.4729e-01,  8.2930e-02,  2.8941e-01,\n",
       "           5.7920e-02, -3.3508e-02, -3.4210e-01, -6.1995e-02,  2.4642e-01,\n",
       "          -1.7357e-01,  4.4184e-02, -5.6078e-01, -3.9045e-01,  2.0384e-01,\n",
       "          -3.1155e-01, -5.7872e-02,  3.9738e-01,  4.1236e-01, -3.4425e-02],\n",
       "         [ 3.9604e-01,  3.4733e-01, -2.9846e-02,  5.7324e-02,  2.4494e-01,\n",
       "           8.2951e-02, -3.3148e-02, -2.4405e-01, -5.3817e-02,  2.1948e-01,\n",
       "          -2.1557e-01,  6.1445e-02, -4.4060e-01, -3.4573e-01,  2.2753e-01,\n",
       "          -3.0093e-01, -8.8049e-02,  3.0201e-01,  3.6247e-01, -3.2339e-02],\n",
       "         [ 4.6832e-01,  4.0552e-01, -9.7796e-02,  8.2112e-02,  2.2042e-01,\n",
       "           5.8492e-02, -3.2428e-02, -3.0590e-01, -3.7635e-02,  2.1735e-01,\n",
       "          -1.9664e-01,  2.1149e-02, -5.2906e-01, -3.3648e-01,  1.9035e-01,\n",
       "          -2.7099e-01, -4.2851e-02,  3.9382e-01,  4.2560e-01, -1.6305e-02]]],\n",
       "       grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_head = AttentionHead(20, 20)\n",
    "attn_head(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58182e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c60f65c",
   "metadata": {},
   "source": [
    "The multi-head attention block simply applies multiple attention heads, then concatenates the outputs and applies a single linear projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44b03693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll supress logging from the scaled dot product attention now\n",
    "logger.setLevel(TensorLoggingLevels.attention_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7637d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    level = TensorLoggingLevels.multihead_attention_block\n",
    "    def __init__(self,d_model:int,d_feature:int,n_heads:int,dropout:float=0.1)->None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_feature = d_feature\n",
    "        self.num_heads = n_heads\n",
    "        \n",
    "        assert d_model == d_feature*n_heads\n",
    "        \n",
    "        # Note that this is very inefficient:\n",
    "        # I am merely implementing the heads separately because it is \n",
    "        # easier to understand this way\n",
    "        \n",
    "        self.attn_heads = nn.ModuleList([\n",
    "            AttentionHead(d_model,d_feature,dropout) for _ in range(self.num_heads)\n",
    "        ])\n",
    "        \n",
    "        self.projection = nn.Linear(d_feature*n_heads,d_model)\n",
    "    \n",
    "    def forward(self,q:Tensor,k:Tensor,v:Tensor,mask:Tensor=None)->Tensor:\n",
    "        log_size(q,'input queries')\n",
    "        x = [attn(q,k,v,mask=mask) for i,attn in enumerate(self.attn_heads)]\n",
    "        log_size(x[0],'output of signle head')\n",
    "        \n",
    "        # reconcatenate\n",
    "        x = torch.cat(x,dim=Dim.feature) #(batch_size,seq_len,d_feature*n_heads)\n",
    "        log_size(x,'concatenated output')\n",
    "        x = self.projection(x)#(batch_size,seq_len,d_feature)\n",
    "        log_size(x,'projected output')\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2953f8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MultiHeadAttention] input queries size=torch.Size([5, 10, 160])\n",
      "[AttentionHead] queries,keys,values size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries,keys,values size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries,keys,values size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries,keys,values size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries,keys,values size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries,keys,values size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries,keys,values size=torch.Size([5, 10, 20])\n",
      "[AttentionHead] queries,keys,values size=torch.Size([5, 10, 20])\n",
      "[MultiHeadAttention] output of signle head size=torch.Size([5, 10, 20])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 10, 160])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 10, 160])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0511, -0.2162, -0.0687,  ..., -0.2284, -0.1313,  0.0634],\n",
       "         [ 0.0507, -0.1710,  0.0064,  ..., -0.1789, -0.0826,  0.0415],\n",
       "         [-0.0147, -0.1924, -0.0692,  ..., -0.1898, -0.1208,  0.0776],\n",
       "         ...,\n",
       "         [-0.0007, -0.1952, -0.0171,  ..., -0.1774, -0.1086,  0.0372],\n",
       "         [-0.0367, -0.1986, -0.0429,  ..., -0.1955, -0.1282,  0.0520],\n",
       "         [ 0.0745, -0.1993,  0.0189,  ..., -0.1806, -0.0612,  0.0701]],\n",
       "\n",
       "        [[-0.0105, -0.1297, -0.1032,  ..., -0.1775, -0.1145,  0.1008],\n",
       "         [ 0.0313, -0.1485, -0.0542,  ..., -0.1894, -0.1066,  0.0829],\n",
       "         [ 0.0641, -0.1349, -0.0294,  ..., -0.1749, -0.1080,  0.0809],\n",
       "         ...,\n",
       "         [ 0.0311, -0.1679, -0.0134,  ..., -0.1700, -0.1206,  0.0759],\n",
       "         [ 0.0374, -0.1427, -0.0724,  ..., -0.1909, -0.0974,  0.0973],\n",
       "         [ 0.0078, -0.1118, -0.0805,  ..., -0.1774, -0.1151,  0.0668]],\n",
       "\n",
       "        [[ 0.0048, -0.0978, -0.0691,  ..., -0.1836, -0.1724, -0.0024],\n",
       "         [ 0.0533, -0.0943, -0.0861,  ..., -0.1703, -0.1343,  0.0234],\n",
       "         [-0.0054, -0.1100, -0.1242,  ..., -0.2063, -0.1625,  0.0221],\n",
       "         ...,\n",
       "         [ 0.0407, -0.0998, -0.0771,  ..., -0.1835, -0.1508,  0.0076],\n",
       "         [-0.0438, -0.1222, -0.0111,  ..., -0.1320, -0.1573, -0.0015],\n",
       "         [ 0.0044, -0.1036, -0.0550,  ..., -0.1883, -0.1697,  0.0061]],\n",
       "\n",
       "        [[-0.0190, -0.1761,  0.0016,  ..., -0.1991, -0.0791,  0.0554],\n",
       "         [-0.0047, -0.1721, -0.0229,  ..., -0.2211, -0.0836,  0.0488],\n",
       "         [ 0.0217, -0.1937, -0.0284,  ..., -0.2141, -0.0837,  0.0589],\n",
       "         ...,\n",
       "         [ 0.0162, -0.1782, -0.0348,  ..., -0.2413, -0.0735,  0.0622],\n",
       "         [-0.0522, -0.1727,  0.0076,  ..., -0.1982, -0.0867,  0.0328],\n",
       "         [-0.0173, -0.1483, -0.0949,  ..., -0.2139, -0.0843,  0.0668]],\n",
       "\n",
       "        [[-0.0240, -0.1173, -0.0497,  ..., -0.1709, -0.1646, -0.0023],\n",
       "         [-0.0213, -0.1196, -0.0394,  ..., -0.1781, -0.1738, -0.0308],\n",
       "         [-0.0091, -0.0879, -0.0453,  ..., -0.1900, -0.1485, -0.0234],\n",
       "         ...,\n",
       "         [ 0.0096, -0.1065, -0.0203,  ..., -0.1584, -0.1581, -0.0392],\n",
       "         [ 0.0183, -0.1019, -0.0665,  ..., -0.1779, -0.1548, -0.0148],\n",
       "         [-0.0081, -0.1182,  0.0047,  ..., -0.1542, -0.1635, -0.0345]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads = MultiHeadAttention(20 * 8, 20, 8)\n",
    "heads(q.repeat(1, 1, 8), \n",
    "      k.repeat(1, 1, 8), \n",
    "      v.repeat(1, 1, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ee4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4af84d77",
   "metadata": {},
   "source": [
    "\n",
    "# The Encoder\n",
    "\n",
    "With these core components in place, implementing the encoder is pretty easy.\n",
    "\n",
    "\n",
    "The encoder consists of the following components:\n",
    "\n",
    "    A multi-head attention block\n",
    "    A simple feedforward neural network\n",
    "\n",
    "These components are connected using residual connections and layer normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecb6583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll supress logging from the individual attention heads\n",
    "logger.setLevel(TensorLoggingLevels.multihead_attention_block)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13e0ba8",
   "metadata": {},
   "source": [
    "Layer normalization is similar to batch normalization, but normalizes across the feature dimension instead of the batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7735c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,d_model:int,eps:float=1e-8)->None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self,x:Tensor)->Tensor:\n",
    "        mean = x.mean(-1,keepdim=True)\n",
    "        std = x.std(-1,keepdim=True)\n",
    "        return self.gamma * (x - mean)/(std + self.eps) + self.beta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea2e0e3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The encoder just stacks these together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9304f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    level = TensorLoggingLevels.enc_dec_block\n",
    "    def __init__(self,d_model:int=512,d_feature:int=64,d_ff:int=2048,n_heads:int=8,dropout:float=0.1)->None:\n",
    "        \n",
    "        super().__init__()\n",
    "        self.attn_head = MultiHeadAttention(d_model, d_feature, n_heads, dropout)\n",
    "        self.layer_norm1 = LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.position_wise_feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "        self.layer_norm2 = LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x:Tensor, mask:Tensor=None)->Tensor:\n",
    "        log_size(x, \"Encoder block input\")\n",
    "        att = self.attn_head(x, x, x, mask=mask)\n",
    "        log_size(x, \"Attention output\")\n",
    "        # Apply normalization and residual connection\n",
    "        x = x + self.dropout(self.layer_norm1(att))\n",
    "        # Apply position-wise feedforward network\n",
    "        pos = self.position_wise_feed_forward(x)\n",
    "        log_size(x, \"Feedforward output\")\n",
    "        # Apply normalization and residual connection\n",
    "        x = x + self.dropout(self.layer_norm2(pos))\n",
    "        log_size(x, \"Encoder size output\")\n",
    "        return x\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c3f29a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EncoderBlock] Encoder block input size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] input queries size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] output of signle head size=torch.Size([5, 10, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 10, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 10, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 10, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 10, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8192,  2.3789,  1.8456,  ...,  0.5327,  2.4587, -2.0722],\n",
       "         [ 0.9339,  1.8649,  2.3383,  ..., -0.2168,  1.9650, -1.7625],\n",
       "         [ 2.1261,  2.1873,  1.9888,  ...,  0.8242,  1.7350, -2.3299],\n",
       "         ...,\n",
       "         [ 1.4683,  0.3586,  0.9493,  ..., -1.1030,  2.2486, -1.2379],\n",
       "         [ 1.7434,  2.4278,  1.8904,  ..., -0.5588,  1.8694, -1.2652],\n",
       "         [ 1.6837,  1.2186,  1.6494,  ..., -0.1739,  1.1170, -2.0326]],\n",
       "\n",
       "        [[ 1.9094,  1.3976,  2.1129,  ...,  0.5157,  2.7508, -1.8893],\n",
       "         [ 2.0656,  1.6296,  2.4549,  ...,  0.0964,  3.1609, -1.7532],\n",
       "         [-0.1060,  1.2345,  2.2978,  ...,  0.5943,  1.9315, -2.3323],\n",
       "         ...,\n",
       "         [ 1.0247,  2.5539,  1.6837,  ...,  0.5987,  2.9148, -1.8273],\n",
       "         [ 1.7906,  2.0697,  1.0290,  ...,  1.0575,  2.3941, -2.4083],\n",
       "         [ 1.7945,  1.1808,  1.7679,  ...,  0.5292,  2.0943, -2.7917]],\n",
       "\n",
       "        [[ 1.1526,  2.7424,  2.4824,  ...,  0.8795,  1.2366, -1.9735],\n",
       "         [ 0.6394,  2.2348,  1.7236,  ...,  0.4047,  3.2574, -2.0357],\n",
       "         [ 1.5295,  1.9119,  2.8059,  ..., -0.2807,  3.0651, -1.9691],\n",
       "         ...,\n",
       "         [ 1.3311,  1.6098,  3.0154,  ...,  1.0115,  2.2924, -1.2779],\n",
       "         [ 1.1059,  1.0041,  2.2380,  ...,  1.3229,  3.1778, -1.3972],\n",
       "         [ 1.7722,  0.3581,  0.7139,  ...,  1.8130,  1.6018, -1.4781]],\n",
       "\n",
       "        [[ 1.7843,  1.0189,  1.7988,  ..., -0.2962,  2.7523, -2.2228],\n",
       "         [ 1.4239,  2.3074,  1.0939,  ...,  0.8456,  2.4168, -1.6675],\n",
       "         [ 2.0543,  0.3421,  2.4102,  ..., -0.5487,  2.4762, -1.9073],\n",
       "         ...,\n",
       "         [ 1.9965,  0.9836,  2.0273,  ..., -0.0316,  2.0655,  0.1461],\n",
       "         [ 1.8050,  1.3226,  1.5176,  ...,  0.3126,  2.5377, -2.6009],\n",
       "         [ 1.6126,  1.5516,  1.5920,  ..., -0.1475,  2.1626, -1.7085]],\n",
       "\n",
       "        [[ 2.5327,  0.8792,  1.4870,  ..., -0.3656,  2.7191, -2.2192],\n",
       "         [ 2.1726,  1.0947,  0.8311,  ...,  0.1576,  2.0638, -1.7810],\n",
       "         [ 1.7663,  1.3792,  1.5615,  ...,  0.0973,  2.5268, -1.1717],\n",
       "         ...,\n",
       "         [ 2.2785,  1.1297,  1.2326,  ...,  0.0682,  2.2806, -1.1393],\n",
       "         [ 0.4320,  1.7873,  2.2468,  ..., -0.0778,  1.6264, -1.9095],\n",
       "         [ 1.4564,  2.6118,  1.8144,  ..., -1.1555,  1.8736, -1.6577]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = EncoderBlock()\n",
    "enc(torch.rand(5, 10, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e590a3db",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The encoder consists of 6 consecutive encoder blocks, so can simply be implemented like the following\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e00478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    level = TensorLoggingLevels.enc_dec\n",
    "    def __init__(self,n_blocks:int=6,d_model:int=512,n_heads:int=8,d_ff:int=2048,dropout:float=0.1)->None:\n",
    "        super().__init__()\n",
    "        self.encoders = nn.ModuleList([\n",
    "            EncoderBlock(d_model=d_model, d_feature=d_model // n_heads,\n",
    "                         d_ff=d_ff, dropout=dropout)\n",
    "            for _ in range(n_blocks)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x: torch.FloatTensor, mask:Tensor=None)->Tensor:\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09251ee1",
   "metadata": {},
   "source": [
    "\n",
    "The Decoder\n",
    "\n",
    "The decoder is mostly the same as the encoder. There's just one additional multi-head attention block that takes the target sentence as input.\n",
    "\n",
    "\n",
    "The keys and values are the outputs of the encoder, and the queries are the outputs of the multi-head attention over the target entence embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a9a7ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    level = TensorLoggingLevels.enc_dec_block\n",
    "    def __init__(self, d_model:int=512, d_feature:int=64,\n",
    "                 d_ff:int=2048, n_heads:int=8, dropout:float=0.1):\n",
    "        super().__init__()\n",
    "        self.masked_attn_head = MultiHeadAttention(d_model, d_feature, n_heads, dropout)\n",
    "        self.attn_head = MultiHeadAttention(d_model, d_feature, n_heads, dropout)\n",
    "        self.position_wise_feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "\n",
    "        self.layer_norm1 = LayerNorm(d_model)\n",
    "        self.layer_norm2 = LayerNorm(d_model)\n",
    "        self.layer_norm3 = LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x:Tensor, enc_out:Tensor, \n",
    "                src_mask:Tensor=None, tgt_mask:Tensor=None)->Tensor:\n",
    "        # Apply attention to inputs\n",
    "        att = self.masked_attn_head(x, x, x, mask=src_mask)\n",
    "        x = x + self.dropout(self.layer_norm1(att))\n",
    "        # Apply attention to the encoder outputs and outputs of the previous layer\n",
    "        att = self.attn_head(x,enc_out,enc_out,tgt_mask)\n",
    "        x = x + self.dropout(self.layer_norm2(att))\n",
    "        # Apply position-wise feedforward network\n",
    "        pos = self.position_wise_feed_forward(x)\n",
    "        x = x + self.dropout(self.layer_norm2(pos))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8ea1c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EncoderBlock] Encoder block input size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] input queries size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] output of signle head size=torch.Size([5, 10, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 10, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 10, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 10, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] input queries size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] output of signle head size=torch.Size([5, 10, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] input queries size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] output of signle head size=torch.Size([5, 10, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 10, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 10, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2615e+00, -1.8722e+00,  2.2510e+00,  ...,  2.9517e-01,\n",
       "           9.4605e-01,  2.6810e-01],\n",
       "         [-8.9229e-01, -3.7514e+00,  2.5797e+00,  ..., -3.6178e-01,\n",
       "          -5.6768e-02,  1.4426e+00],\n",
       "         [-7.3190e-01, -3.3193e+00,  2.3307e+00,  ...,  1.3170e-01,\n",
       "           4.4112e-01,  7.1429e-01],\n",
       "         ...,\n",
       "         [-1.7197e+00, -1.1160e+00,  2.4876e+00,  ...,  2.5105e-01,\n",
       "          -3.0039e-01, -3.1281e-01],\n",
       "         [-2.4196e+00, -3.6260e+00,  2.2973e+00,  ..., -4.2077e-01,\n",
       "           2.5133e+00, -6.5064e-01],\n",
       "         [-1.6447e+00, -2.5834e+00,  1.2424e+00,  ...,  1.9222e-03,\n",
       "          -4.5628e-01,  8.8122e-01]],\n",
       "\n",
       "        [[-1.2983e+00, -9.8285e-01,  1.5088e+00,  ..., -4.7545e-01,\n",
       "          -3.6731e-01, -5.1744e-01],\n",
       "         [-1.3096e+00, -2.6271e+00,  3.9300e+00,  ...,  1.2478e+00,\n",
       "           2.2432e-01, -8.9195e-01],\n",
       "         [-1.9818e+00, -1.3137e+00,  3.6184e+00,  ..., -1.3409e+00,\n",
       "           1.5128e+00,  6.6361e-01],\n",
       "         ...,\n",
       "         [-1.6676e+00, -3.6403e+00,  4.1778e+00,  ..., -8.4668e-01,\n",
       "           5.1815e-01,  9.2671e-01],\n",
       "         [-3.1631e-01, -1.4415e+00,  3.6154e+00,  ..., -4.2385e-01,\n",
       "           6.1260e-01,  4.2732e-01],\n",
       "         [ 8.4766e-01, -3.5381e+00,  3.7590e+00,  ..., -9.0245e-01,\n",
       "           1.4582e-01, -9.1699e-01]],\n",
       "\n",
       "        [[-2.7534e-01, -1.6962e+00,  2.2346e+00,  ..., -6.7886e-01,\n",
       "          -1.1625e+00, -4.0432e-02],\n",
       "         [-2.4668e+00, -3.3798e+00,  2.3122e+00,  ..., -7.0049e-01,\n",
       "           4.9579e-01,  4.9435e-02],\n",
       "         [-2.2451e+00, -2.8339e+00,  2.0998e+00,  ...,  4.0185e-01,\n",
       "           6.9736e-02,  2.7093e-01],\n",
       "         ...,\n",
       "         [-2.2063e+00, -3.9343e+00,  4.2561e-01,  ..., -8.1270e-01,\n",
       "           8.1471e-01, -5.2269e-01],\n",
       "         [-2.6728e+00, -3.4981e+00,  1.8408e+00,  ..., -6.7976e-01,\n",
       "           2.5589e-01, -6.5503e-01],\n",
       "         [-2.3968e+00, -1.5551e+00,  2.4885e+00,  ...,  3.6129e-01,\n",
       "           1.0061e+00, -1.9986e-01]],\n",
       "\n",
       "        [[-4.2795e-01, -3.0022e+00,  1.4618e+00,  ..., -7.6007e-01,\n",
       "           1.3508e-01,  3.4718e-02],\n",
       "         [-1.8027e+00, -2.4215e+00,  1.8835e+00,  ..., -1.1718e+00,\n",
       "           3.5706e-01, -1.1199e+00],\n",
       "         [-2.3191e+00, -1.5474e+00,  3.1640e+00,  ..., -1.8930e+00,\n",
       "           7.6405e-01, -4.3399e-01],\n",
       "         ...,\n",
       "         [-1.3158e+00, -3.2751e+00,  2.3819e+00,  ..., -8.6080e-01,\n",
       "           1.4321e-01, -9.5702e-01],\n",
       "         [-1.5109e+00, -3.6670e+00,  1.8132e+00,  ..., -1.7385e+00,\n",
       "           6.8184e-01,  8.9505e-01],\n",
       "         [-1.0570e+00, -1.4551e+00,  2.9269e+00,  ..., -7.9866e-01,\n",
       "           3.3220e-01, -2.0997e-01]],\n",
       "\n",
       "        [[-8.9654e-01, -3.3848e+00,  2.5714e+00,  ..., -2.9425e-01,\n",
       "           4.1961e-01, -6.4067e-02],\n",
       "         [-3.2811e-01, -1.8982e+00,  2.5833e+00,  ...,  1.4365e+00,\n",
       "           7.4386e-01, -2.0353e-01],\n",
       "         [-2.2909e+00, -2.9579e+00,  2.5552e-02,  ...,  1.0598e+00,\n",
       "           1.1886e+00,  3.8263e-02],\n",
       "         ...,\n",
       "         [-1.7121e+00, -2.1988e+00,  1.6773e+00,  ..., -8.2911e-01,\n",
       "          -2.6141e-03, -5.1905e-02],\n",
       "         [-3.0224e-01, -2.8210e+00,  2.9637e+00,  ..., -4.8638e-01,\n",
       "           1.7799e-01, -7.1652e-01],\n",
       "         [-2.2956e+00, -1.6985e+00,  1.9532e+00,  ...,  2.4200e-01,\n",
       "           2.0641e-01, -1.3853e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = DecoderBlock()\n",
    "dec(torch.rand(5, 10, 512), enc(torch.rand(5, 10, 512)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a88cfc6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Again, the decoder is just a stack of the underlying block so is simple to implement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bf7c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    level = TensorLoggingLevels.enc_dec\n",
    "    def __init__(self, n_blocks=6, d_model=512, d_feature=64,\n",
    "                 d_ff=2048, n_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.position_embedding = PositionalEmbedding(d_model)\n",
    "        self.decoders = nn.ModuleList([\n",
    "            DecoderBlock(d_model=d_model, d_feature=d_model // n_heads,\n",
    "                         d_ff=d_ff, dropout=dropout)\n",
    "            for _ in range(n_blocks)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x: torch.FloatTensor, \n",
    "                enc_out: torch.FloatTensor, \n",
    "                src_mask=None, tgt_mask=None):\n",
    "        for decoder in self.decoders:\n",
    "            x = decoder(x, enc_out, src_mask,tgt_mask)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c68e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4289796f",
   "metadata": {},
   "source": [
    "\n",
    "# Positional Embeddings\n",
    "\n",
    "Attention blocks are just simple matrix multiplications: therefore they don't have any notion of order! The Transformer explicitly adds positional information via the positional embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18c2d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    level = 1\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super().__init__()        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.weight = nn.Parameter(pe, requires_grad=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.weight[:, :x.size(1), :] # (1, Seq, Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "674f03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordPositionEmbedding(nn.Module):\n",
    "    level = 1\n",
    "    def __init__(self, vocab_size, d_model=512):\n",
    "        super().__init__()\n",
    "        self.word_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model)\n",
    "        \n",
    "    def forward(self, x: torch.LongTensor, mask=None) -> torch.FloatTensor:\n",
    "        return self.word_embedding(x) + self.position_embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "838ce473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] input queries size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] output of signle head size=torch.Size([5, 30, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] input queries size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] output of signle head size=torch.Size([5, 30, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] input queries size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] output of signle head size=torch.Size([5, 30, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] input queries size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] output of signle head size=torch.Size([5, 30, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] input queries size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] output of signle head size=torch.Size([5, 30, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] input queries size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] output of signle head size=torch.Size([5, 30, 64])\n",
      "[MultiHeadAttention] concatenated output size=torch.Size([5, 30, 512])\n",
      "[MultiHeadAttention] projected output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6346e-01,  1.2155e-01, -1.3424e+00,  ...,  8.9453e+00,\n",
       "          -9.3236e-01,  4.7319e-02],\n",
       "         [ 1.4943e+00, -2.8081e+00, -2.6555e+00,  ...,  8.0715e+00,\n",
       "          -3.1153e+00, -3.5599e+00],\n",
       "         [ 1.4497e+00, -3.9774e+00, -3.1722e+00,  ...,  7.6725e+00,\n",
       "           5.8214e-01,  2.7863e+00],\n",
       "         ...,\n",
       "         [-3.5097e+00, -1.9654e+00, -2.6983e+00,  ...,  9.6948e+00,\n",
       "          -1.0771e+00,  2.2490e+00],\n",
       "         [-1.3410e+00, -3.8619e+00, -3.9282e+00,  ...,  1.0554e+01,\n",
       "          -1.1946e+00,  1.8432e+00],\n",
       "         [-8.7771e-01, -2.0514e+00, -3.6552e+00,  ...,  9.7941e+00,\n",
       "          -2.6640e+00,  2.7551e+00]],\n",
       "\n",
       "        [[-8.1897e-02, -5.5409e+00, -3.5413e+00,  ...,  6.6499e+00,\n",
       "           4.8690e-01,  3.5351e+00],\n",
       "         [ 3.9006e+00, -3.7371e-01, -6.2669e-01,  ...,  5.7385e+00,\n",
       "           3.2112e+00,  3.2876e+00],\n",
       "         [ 2.4043e-01,  6.7510e-01, -5.3848e-01,  ...,  9.6645e+00,\n",
       "          -6.3463e-01,  2.2420e+00],\n",
       "         ...,\n",
       "         [-1.0896e+00, -2.1972e+00, -2.7894e+00,  ...,  8.1504e+00,\n",
       "           1.5991e+00,  2.7946e+00],\n",
       "         [ 3.0772e+00, -3.5087e+00, -1.7522e+00,  ...,  2.8325e+00,\n",
       "          -2.4476e+00,  2.2903e+00],\n",
       "         [-9.9405e-01, -5.1707e+00, -3.2554e+00,  ...,  4.8565e+00,\n",
       "          -6.5321e+00,  2.6600e+00]],\n",
       "\n",
       "        [[-4.5409e+00, -3.2636e+00, -1.9237e+00,  ...,  5.9086e+00,\n",
       "          -2.5313e+00,  3.7070e+00],\n",
       "         [-7.6507e-01, -3.6377e+00,  5.4412e-04,  ...,  5.9203e+00,\n",
       "          -2.5104e+00,  6.1900e+00],\n",
       "         [ 1.4000e+00, -5.4072e+00,  7.9301e-01,  ...,  7.4173e+00,\n",
       "           1.4474e+00,  2.5349e+00],\n",
       "         ...,\n",
       "         [ 1.2563e+00, -1.9105e+00,  6.0105e-01,  ...,  5.4457e+00,\n",
       "          -2.6946e+00,  1.8955e+00],\n",
       "         [ 1.4370e-01, -3.0052e+00,  2.1739e+00,  ...,  6.0276e+00,\n",
       "          -1.5127e+00,  2.3147e+00],\n",
       "         [-7.9702e-01,  8.3035e-02, -1.0415e-01,  ...,  9.0685e+00,\n",
       "          -1.8684e+00,  3.8238e+00]],\n",
       "\n",
       "        [[ 6.1899e-01, -2.2347e+00, -2.3919e+00,  ...,  6.5448e+00,\n",
       "           5.6949e-01,  3.2589e+00],\n",
       "         [ 3.4056e-01,  4.1435e-01, -4.3644e+00,  ...,  2.4769e+00,\n",
       "          -1.4685e+00,  2.0241e+00],\n",
       "         [ 1.4089e+00, -1.8537e+00, -1.3489e+00,  ...,  6.4685e+00,\n",
       "           1.4808e+00,  4.2189e+00],\n",
       "         ...,\n",
       "         [ 2.9577e-02, -2.6583e+00, -1.0351e+00,  ...,  6.6065e+00,\n",
       "           9.1812e-01, -2.2945e+00],\n",
       "         [ 3.1341e+00, -1.5445e+00, -1.7791e+00,  ...,  3.7936e+00,\n",
       "          -3.0066e+00,  2.9686e+00],\n",
       "         [ 1.3608e+00, -3.1309e-01, -1.2448e+00,  ...,  4.0131e+00,\n",
       "          -2.5669e+00,  2.5590e+00]],\n",
       "\n",
       "        [[-1.1133e+00,  2.0747e+00, -2.6875e+00,  ...,  5.6449e+00,\n",
       "           2.8441e+00,  1.8206e+00],\n",
       "         [ 7.7648e-01, -2.2138e+00, -1.9602e+00,  ...,  6.5234e+00,\n",
       "           1.7246e+00,  1.5391e-01],\n",
       "         [-6.5759e-01, -3.1767e-01, -3.7048e+00,  ...,  4.9989e+00,\n",
       "           3.1027e-02, -9.3303e-01],\n",
       "         ...,\n",
       "         [ 2.5359e+00, -4.7123e+00, -4.7502e+00,  ...,  2.8553e+00,\n",
       "           7.6165e-01, -1.6025e-01],\n",
       "         [-1.4627e+00,  1.7486e-02, -2.3658e+00,  ...,  7.6226e+00,\n",
       "           2.7384e+00,  1.5626e+00],\n",
       "         [ 1.6852e+00, -3.5607e+00, -5.4268e+00,  ...,  6.4370e+00,\n",
       "           1.2260e+00,  2.6260e+00]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = WordPositionEmbedding(1000)\n",
    "encoder = TransformerEncoder()\n",
    "encoder(emb(torch.randint(1000, (5, 30))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee5325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10f6ca7c",
   "metadata": {},
   "source": [
    "\n",
    "# Putting it All Together\n",
    "\n",
    "Let's put everything together now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "182e9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll supress logging from the scaled dot product attention now\n",
    "logger.setLevel(TensorLoggingLevels.enc_dec_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b928eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = WordPositionEmbedding(1000)\n",
    "encoder = TransformerEncoder()\n",
    "decoder = TransformerDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d47727c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder block input size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Attention output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Feedforward output size=torch.Size([5, 30, 512])\n",
      "[EncoderBlock] Encoder size output size=torch.Size([5, 30, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[  4.1734,  -1.1576,  -9.5102,  ...,   1.2630,   1.9948,   2.2728],\n",
       "         [  5.4421,   3.6629,  -3.3422,  ...,  -0.3909,  -0.8506,   3.4127],\n",
       "         [  5.3183,   1.8572, -11.6261,  ...,  -0.3822,  -2.3306,   4.0876],\n",
       "         ...,\n",
       "         [  4.2614,  -0.8675, -12.0535,  ...,   1.8744,   0.1623,   8.5918],\n",
       "         [ -1.5347,  -1.1825,  -8.7053,  ...,  -0.0344,  -1.1608,   2.3443],\n",
       "         [  3.7099,   0.3772,  -8.5302,  ...,   5.5246,  -1.0878,   5.6007]],\n",
       "\n",
       "        [[  3.0506,   3.3710,  -9.0028,  ...,   3.7933,   2.6592,  -1.5478],\n",
       "         [  2.2161,  -1.3730,  -5.7518,  ...,   3.8405,   0.6954,   5.6836],\n",
       "         [  2.3288,  -0.2974,  -9.2382,  ...,   3.4638,   0.8501,   7.2387],\n",
       "         ...,\n",
       "         [  3.4776,  -3.0073,  -5.2200,  ...,   3.3558,   1.6917,   1.0592],\n",
       "         [  1.7754,  -2.0260,  -6.0141,  ...,   4.4846,   1.0798,   5.5728],\n",
       "         [  1.6747,   1.0592, -14.2253,  ...,   3.2874,  -1.5582,   7.7551]],\n",
       "\n",
       "        [[ -1.0860,  -2.2918,  -8.1923,  ...,  -0.4597,  -0.8735,   0.0968],\n",
       "         [ -0.3743,   1.3482, -10.1812,  ...,   2.8837,  -0.5627,   1.2570],\n",
       "         [  2.3430,  -7.9219,  -9.7449,  ...,   3.4815,   4.4167,  -1.5162],\n",
       "         ...,\n",
       "         [  3.1321,   1.7655, -11.9688,  ...,  -0.6140,   0.6220,   2.5589],\n",
       "         [ -4.6564,  -3.3974,  -8.2628,  ...,   0.8342,  -0.2310,  -1.4130],\n",
       "         [  0.6920,  -0.7988, -13.7871,  ...,   0.7251,   1.0048,  -3.2086]],\n",
       "\n",
       "        [[  1.5511,   4.5026,  -9.7766,  ...,  -1.5028,  -5.1168,   0.3255],\n",
       "         [  8.2668,   3.4308,  -7.1560,  ...,  -0.2332,  -3.7205,   2.0438],\n",
       "         [  1.4817,   2.0189, -12.0722,  ...,   2.2192,  -3.3734,   4.4782],\n",
       "         ...,\n",
       "         [  3.6156,   2.7597,  -7.4789,  ...,   0.1836,  -1.1462,   2.8865],\n",
       "         [  0.2211,   2.0930, -11.5010,  ...,   1.8875,  -1.4160,   1.2994],\n",
       "         [  3.9552,   0.7460, -10.9953,  ...,   4.4809,  -4.5791,   2.7295]],\n",
       "\n",
       "        [[  1.3612,  -2.2732,  -9.4840,  ...,  -0.3305,  -3.1702,  -0.8361],\n",
       "         [ -0.8160,   0.0991, -10.0796,  ...,   3.6265,  -1.8615,  -1.2410],\n",
       "         [  2.3706,  -2.1348,  -7.7317,  ...,   4.7635,  -2.6033,  -0.2820],\n",
       "         ...,\n",
       "         [  2.9598,  -0.7335,  -7.8337,  ...,   1.9276,  -0.0867,   2.5072],\n",
       "         [ -0.5446,  -3.0528,  -1.6611,  ...,   0.1374,  -2.8907,   4.2171],\n",
       "         [ -0.5615,   1.3285, -10.0082,  ...,   2.9709,  -3.6061,   1.7170]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_ids = torch.randint(1000, (5, 30))\n",
    "tgt_ids = torch.randint(1000, (5, 30))\n",
    "x = encoder(emb(src_ids))\n",
    "decoder(emb(tgt_ids), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5f3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
